{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVxroAnJVd-Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "fakedata = pd.read_csv('/content/Lots_Permissions_CH5_fakedata (1).csv')\n",
        "lot_names = set(fakedata['Lot Name'])\n",
        "\n",
        "\n",
        "\n",
        "def isSliceCyclc(slice):\n",
        "  print(slice.loc[0, 'Start Time - Daily'], slice.loc[0, 'End Time - Daily'])\n",
        "  if slice.loc[0, 'Start Time - Daily'] == slice.loc[0, 'End Time - Daily']:\n",
        "    flag = True\n",
        "  else:\n",
        "    flag = False\n",
        "\n",
        "  start = slice.loc[0, 'Start Time - Daily']\n",
        "  print(start)\n",
        "  for idx, row in slice.iloc[1:,:].iterrows():\n",
        "    print(row['Start Time - Daily'],row['End Time - Daily'])\n",
        "    if row['End Time - Daily'] == start:\n",
        "      flag = True\n",
        "      break\n",
        "\n",
        "    if row['Start Time - Daily'] != slice.loc[idx-1, 'End Time - Daily']:\n",
        "      flag = False\n",
        "      break\n",
        "\n",
        "  return flag\n",
        "\n",
        "def check_cyclic_lots(data, lot_names):\n",
        "  cyclic_lots_weekdays = []\n",
        "  non_cyclic_lots_weekdays = []\n",
        "  cyclic_lots_weekends = []\n",
        "  non_cyclic_lots_weekends = []\n",
        "\n",
        "\n",
        "  for lot_name in lot_names:\n",
        "    print(lot_name)\n",
        "    slice = data[(data['Lot Name']==lot_name) & (data['Enforcement Days']=='Weekdays')].reset_index()\n",
        "    if len(slice)!=0:\n",
        "      if isSliceCyclc(slice):\n",
        "        cyclic_lots_weekdays.append(lot_name)\n",
        "      else:\n",
        "        non_cyclic_lots_weekdays.append(lot_name)\n",
        "    slice = data[(data['Lot Name']==lot_name) & (data['Enforcement Days']=='Weekends')].reset_index()\n",
        "    if len(slice)!=0:\n",
        "      if isSliceCyclc(slice):\n",
        "        cyclic_lots_weekends.append(lot_name)\n",
        "      else:\n",
        "        non_cyclic_lots_weekends.append(lot_name)\n",
        "    slice = data[(data['Lot Name']==lot_name) & (data['Enforcement Days']=='Always')].reset_index()\n",
        "    if len(slice)!=0:\n",
        "      if isSliceCyclc(slice):\n",
        "        cyclic_lots_weekends.append(lot_name)\n",
        "      else:\n",
        "        non_cyclic_lots_weekends.append(lot_name)\n",
        "  return cyclic_lots_weekdays, non_cyclic_lots_weekdays, cyclic_lots_weekends, non_cyclic_lots_weekends\n",
        "\n",
        "cyclic_lots_weekdays, non_cyclic_lots_weekdays, cyclic_lots_weekends, non_cyclic_lots_weekends = check_cyclic_lots(fakedata, lot_names)\n",
        "print(non_cyclic_lots_weekdays, non_cyclic_lots_weekends)\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def parse_parking_data(df):\n",
        "    \"\"\"\n",
        "    Given a DataFrame 'df' with columns:\n",
        "        - \"Lot Type\"\n",
        "        - \"Physical Location (Yes/No)\"\n",
        "        - \"Parking Lot / Zone Name\"\n",
        "        - \"Posted Restrictions\"\n",
        "        - \"Enforcement Days\"\n",
        "        - \"Start Time - Daily\"\n",
        "        - \"End Time - Daily\"\n",
        "        - ... plus many permit columns (e.g., \"17FAE\", \"A\", \"AA\", etc.)\n",
        "    Return a nested dictionary in the format:\n",
        "\n",
        "    {\n",
        "        lot_name: {\n",
        "            \"Type\": <string>,\n",
        "            \"Physical Location\": <bool>,\n",
        "            \"Permissions\": {\n",
        "                day_type (e.g. \"Weekdays\"): {\n",
        "                    (start_time, end_time): {\n",
        "                        permit_name: bool,\n",
        "                        ...\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        ...\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Identify which columns are permits by excluding known metadata columns\n",
        "    known_columns = {\n",
        "        \"Lot Type \",\n",
        "        \"Physical Location (Yes/No)\",\n",
        "        \"Lot Name\",\n",
        "        \"Posted Restrictions\",\n",
        "        \"Enforcement Days\",\n",
        "        \"Start Time - Daily\",\n",
        "        \"End Time - Daily\",\n",
        "        \"Count Valid Permissions in Lot by Date/Time\",\n",
        "    }\n",
        "\n",
        "    # All other columns are presumably permit columns\n",
        "    permit_columns = [col for col in df.columns if col not in known_columns]\n",
        "\n",
        "    # Our final nested dictionary\n",
        "    lots_dict = {}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        lot_name = str(row[\"Lot Name\"])\n",
        "        lot_type = str(row[\"Lot Type \"])\n",
        "        physical_location_val = str(row[\"Physical Location (Yes/No)\"]).strip().upper()\n",
        "        # Convert \"YES\"/\"NO\" to boolean\n",
        "        physical_location_bool = (physical_location_val == \"YES\")\n",
        "\n",
        "        enforcement_day = str(row[\"Enforcement Days\"]).strip()\n",
        "        start_time_raw = str(row[\"Start Time - Daily\"]).strip()\n",
        "        end_time_raw = str(row[\"End Time - Daily\"]).strip()\n",
        "\n",
        "        # If your dataset uses \"0:00:00\" to mean midnight, you might\n",
        "        # want to convert to \"00:00\" or \"24:00\" for clarity. For example:\n",
        "        # start_time = \"00:00\" if start_time_raw == \"0:00:00\" else start_time_raw\n",
        "        # But here, we just keep them as-is or do minimal cleanup:\n",
        "        start_time = start_time_raw\n",
        "        end_time = end_time_raw\n",
        "\n",
        "        # Initialize lot entry if not present\n",
        "        if lot_name not in lots_dict:\n",
        "            lots_dict[lot_name] = {\n",
        "                \"Type\": lot_type,\n",
        "                \"Physical Location\": physical_location_bool,\n",
        "                \"Permissions\": {}\n",
        "            }\n",
        "\n",
        "        # Prepare to store the permit booleans\n",
        "        permit_dict = {}\n",
        "        for pcol in permit_columns:\n",
        "            val = row[pcol]\n",
        "            # Convert 1 -> True, 0 -> False (or strings \"1\"/\"0\" similarly)\n",
        "            permit_dict[pcol] = bool(val)\n",
        "\n",
        "        # Insert into the nested structure\n",
        "        if enforcement_day not in lots_dict[lot_name][\"Permissions\"]:\n",
        "            lots_dict[lot_name][\"Permissions\"][enforcement_day] = {}\n",
        "\n",
        "        # Use (start_time, end_time) as a tuple key\n",
        "        time_tuple = (start_time, end_time)\n",
        "        lots_dict[lot_name][\"Permissions\"][enforcement_day][time_tuple] = permit_dict\n",
        "\n",
        "    return lots_dict\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta, time  # Import the time class\n",
        "\n",
        "# Convert 'End Time - Daily' to datetime objects\n",
        "fakedata['End Time - Daily'] = pd.to_datetime(fakedata['End Time - Daily'], format='%H:%M:%S').dt.time\n",
        "\n",
        "# Reduce all 'End Time - Daily' times by 1 second, handling midnight case\n",
        "def subtract_one_second(t):\n",
        "    if t == datetime.min.time():  # Check if it's midnight\n",
        "        return time(23, 59, 59)  # Use time class to create time object\n",
        "    else:\n",
        "        return (datetime.combine(datetime.min, t) - timedelta(seconds=1)).time()\n",
        "\n",
        "fakedata['End Time - Daily'] = fakedata['End Time - Daily'].apply(subtract_one_second)\n",
        "\n",
        "# Convert 'End Time - Daily' back to string format\n",
        "fakedata['End Time - Daily'] = fakedata['End Time - Daily'].astype(str)\n",
        "\n",
        "parsed_data = parse_parking_data(fakedata)\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "def make_prefix_mapping_from_df(df, prefix_col=\"Prefix\", perm_col=\"Permissions\"):\n",
        "    \"\"\"\n",
        "    Build a dictionary from a 2-column DataFrame with columns:\n",
        "      prefix_col, perm_col\n",
        "    Rules:\n",
        "      - If prefix appears exactly once in the DF, map prefix -> permission\n",
        "      - If prefix appears multiple times, map prefix-permission -> permission\n",
        "    \"\"\"\n",
        "    # 1) Collect (prefix, permission) pairs\n",
        "    pairs = []\n",
        "    for _, row in df.iterrows():\n",
        "        prefix = str(row[prefix_col]).strip()\n",
        "        perm   = str(row[perm_col]).strip()\n",
        "        # Only add if there's something\n",
        "        if prefix or perm:\n",
        "            pairs.append((prefix, perm))\n",
        "\n",
        "    # 2) Count how many times each prefix occurs\n",
        "    prefix_counts = Counter(pair[0] for pair in pairs)\n",
        "\n",
        "    # 3) Build the dictionary\n",
        "    mapping = {}\n",
        "    seen = set()\n",
        "    for prefix, perm in pairs:\n",
        "        if (prefix, perm) in seen:\n",
        "            # skip duplicates if the exact (prefix, perm) repeats\n",
        "            continue\n",
        "        seen.add((prefix, perm))\n",
        "\n",
        "        if prefix_counts[prefix] == 1:\n",
        "            # Unique prefix => map prefix -> permission\n",
        "            mapping[prefix] = perm\n",
        "        else:\n",
        "            # Duplicate prefix => map \"prefix-permission\" -> permission\n",
        "            mapping[f\"{prefix}-{perm}\"] = perm\n",
        "\n",
        "    return mapping\n",
        "\n",
        "# ------------------------------\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Suppose you have a DataFrame named df_prefix with two columns:\n",
        "    # e.g. df_prefix.columns = [\"Prefix\", \"Permission\"]\n",
        "    #\n",
        "    # For demonstration, let's build a small example DataFrame:\n",
        "\n",
        "    data = pd.read_csv('/content/Permits & Permissions.csv')\n",
        "    df_prefix = data[['Prefix', 'Permissions']]\n",
        "\n",
        "    # Build the dictionary\n",
        "    map_prefix_to_permission = make_prefix_mapping_from_df(df_prefix)\n",
        "\n",
        "    # Print in your requested format\n",
        "    print(\"map_prefix_to_permission = {\")\n",
        "    for k, v in map_prefix_to_permission.items():\n",
        "        print(f\"    '{k}': '{v}',\")\n",
        "    print(\"}\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# Check which values in map_prefix_to_permission are not columns in fakedata\n",
        "missing_cols = []\n",
        "for prefix in map_prefix_to_permission.values():\n",
        "    if prefix not in fakedata.columns:\n",
        "        missing_cols.append(prefix)\n",
        "\n",
        "print(\"Columns in map_prefix_to_permission not found in fakedata:\", missing_cols)\n",
        "\n",
        "# Assuming 'data_hella_new' DataFrame is already loaded\n",
        "\n",
        "def find_non_unique_prefixes(df, column_name='Prefix'):\n",
        "    \"\"\"\n",
        "    Finds and returns a list of non-unique values in the specified column of a DataFrame.\n",
        "    \"\"\"\n",
        "    value_counts = df[column_name].value_counts()\n",
        "    non_unique_values = value_counts[value_counts > 1].index.tolist()\n",
        "    return non_unique_values\n",
        "\n",
        "# Assuming data_hella_new is your DataFrame\n",
        "non_unique_prefixes = find_non_unique_prefixes(data, column_name='Prefix')\n",
        "\n",
        "def is_time_in_tuple(time_str, time_tuple):\n",
        "    \"\"\"\n",
        "    Checks if a time string is within a given time tuple.\n",
        "\n",
        "    Args:\n",
        "        time_str: The time string to check (e.g., \"08:30:00\").\n",
        "        time_tuple: A tuple containing two time strings representing the start and end times (e.g., (\"07:00:00\", \"16:00:00\")).\n",
        "\n",
        "    Returns:\n",
        "        True if the time string falls within the time tuple (inclusive), False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        time_obj = datetime.strptime(time_str, \"%H:%M:%S\").time()\n",
        "        start_time_obj = datetime.strptime(time_tuple[0], \"%H:%M:%S\").time()\n",
        "        end_time_obj = datetime.strptime(time_tuple[1], \"%H:%M:%S\").time()\n",
        "\n",
        "        return start_time_obj <= time_obj <= end_time_obj\n",
        "    except ValueError:\n",
        "        return False # Handle invalid time string format\n",
        "\n",
        "\n",
        "def extract_prefix(permit_no: str) -> str: #Assumption: 5 numbers after prefix\n",
        "  return permit_no[:-5]\n",
        "\n",
        "\n",
        "day_mapper = {\n",
        "    'monday': 'Weekdays',\n",
        "    'tuesday': 'Weekdays',\n",
        "    'wednesday': 'Weekdays',\n",
        "    'thursday': 'Weekdays',\n",
        "    'friday': 'Weekdays',\n",
        "    'saturday': 'Weekends',\n",
        "    'sunday': 'Weekends'\n",
        "}\n",
        "\n",
        "def number_letter_extract(number_letter):\n",
        "  s = \"\"\n",
        "  for idx in range(len(number_letter)-1, -1, -1):\n",
        "    try:\n",
        "      s = number_letter[:idx]\n",
        "      return int(s)\n",
        "\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "\n",
        "\n",
        "def extract_number_from_lot(lot: str)->str:\n",
        "  if 'Lot' in lot:\n",
        "    the_rest = lot[4:]\n",
        "\n",
        "    return number_letter_extract(the_rest)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "JKb8YzVuVhqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "def find_lot_name(input_name: str, lot_names: set) -> dict:\n",
        "    \"\"\"\n",
        "    Takes a string `input_name` and a set of known lot names `lot_names`.\n",
        "    If `input_name` is exactly in `lot_names`, returns [input_name].\n",
        "    Otherwise, it returns a list of the 5 closest lot names.\n",
        "    \"\"\"\n",
        "    # 1) Quick exact check\n",
        "    if input_name in lot_names:\n",
        "        return {1: input_name}\n",
        "\n",
        "    # 2) Build a list from the set so we can index it\n",
        "    lot_names_list = list(lot_names)\n",
        "\n",
        "    # 3) Load a sentence embedding model (or any other embedding method you prefer)\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    # 4) Compute embeddings for all known lot names\n",
        "    lot_embeddings = model.encode(lot_names_list, convert_to_numpy=True)\n",
        "\n",
        "    # 5) Build a FAISS index\n",
        "    embed_dim = lot_embeddings.shape[1]  # Dimension of the embeddings\n",
        "    index = faiss.IndexFlatL2(embed_dim)\n",
        "    index.add(lot_embeddings)\n",
        "\n",
        "    # 6) Compute embedding for input_name\n",
        "    input_embedding = model.encode([input_name], convert_to_numpy=True)\n",
        "\n",
        "    # 7) Search for the top 5 matches\n",
        "    k = 5\n",
        "    distances, indices = index.search(input_embedding, k)\n",
        "\n",
        "    # 8) Return the 5 closest names\n",
        "    closest_matches = {i+1: lot_names_list[idx] for i, idx in enumerate(indices[0])}\n",
        "    return closest_matches"
      ],
      "metadata": {
        "id": "o3IjbV6UVshf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_parking_eligibility():\n",
        "  global non_unique_prefixes\n",
        "  global map_prefix_to_permission\n",
        "  global parsed_data\n",
        "  global lot_names\n",
        "  global day_mapper\n",
        "\n",
        "  permit = str(input(\"Enter permit number: \"))\n",
        "  lot = str(input(\"Enter lot name: \"))\n",
        "  day = str(input(\"Enter day: \"))\n",
        "  time = str(input(\"Enter time: \"))\n",
        "\n",
        "\n",
        "  if lot[0] in \"1234567890\":\n",
        "    lot = f'Lot {lot}'\n",
        "\n",
        "  lot_results = find_lot_name(lot, lot_names)\n",
        "\n",
        "  if len(lot_results) == 1:\n",
        "    lot = lot_results[1]\n",
        "  else:\n",
        "    print(f\"Lot not found. Closest Matches:\\n{lot_results}\")\n",
        "    lot_key = input('Enter Key: ')\n",
        "    lot = lot_results[int(lot_key)]\n",
        "\n",
        "  if 'Lot' in lot:\n",
        "    num = extract_number_from_lot(lot)\n",
        "    lot_perm = 'Lot ' + str(num)\n",
        "  else: lot_perm = lot\n",
        "\n",
        "  # print (lot)\n",
        "  if lot not in lot_names:\n",
        "    if f'Lot {lot}' in lot_names:\n",
        "      lot = f'Lot {lot}'\n",
        "    else:\n",
        "      print(\"Lot not found in data.\")\n",
        "      return\n",
        "\n",
        "  prefix = extract_prefix(permit)\n",
        "  if prefix in non_unique_prefixes:\n",
        "    permit_perm = str(input(f\"Enter Lot you have this {prefix} permit for: \"))\n",
        "    new_prefix = f'{prefix}-{permit_perm}'\n",
        "  else:\n",
        "    new_prefix = prefix\n",
        "  if new_prefix in map_prefix_to_permission:\n",
        "    perm = map_prefix_to_permission[new_prefix]\n",
        "  else:\n",
        "    # if prefix not in map_prefix_to_permission:\n",
        "    #   if f'{prefix}-{lot_perm}' in map_prefix_to_permission:\n",
        "    #     perm = map_prefix_to_permission[f'{prefix}-{lot}']\n",
        "    #   else:\n",
        "    #     print(f'{prefix}-{lot_perm}')\n",
        "    #     print('Invalid Permit Input')\n",
        "    #     return\n",
        "    closest_match = find_lot_name(new_prefix, set(map_prefix_to_permission.keys()))\n",
        "    if len(closest_match) == 1:\n",
        "      perm = map_prefix_to_permission[closest_match[1]]\n",
        "    else:\n",
        "      print(f\"Did you mean:\\n{closest_match}\")\n",
        "      perm_key = input('Enter Key: ')\n",
        "      perm = map_prefix_to_permission[closest_match[int(perm_key)]]\n",
        "\n",
        "\n",
        "  if day.lower() in day_mapper:\n",
        "    day = day_mapper[day.lower()]\n",
        "  else:\n",
        "    print('Invalid Day Input')\n",
        "    return\n",
        "\n",
        "\n",
        "  available_days = list(parsed_data[lot]['Permissions'].keys())\n",
        "  if day not in available_days:\n",
        "    day = 'Always'\n",
        "\n",
        "  available_times = list(parsed_data[lot]['Permissions'][day].keys())\n",
        "\n",
        "  for time_tuple in available_times:\n",
        "    if is_time_in_tuple(time, time_tuple):\n",
        "      print(f'Parking Permission for {lot} with permit {perm} is {parsed_data[lot][\"Permissions\"][day][time_tuple][perm]}')\n",
        "      return\n",
        "  print(f'Parking Permission for {lot} with permit {perm} is not abailable')\n",
        ""
      ],
      "metadata": {
        "id": "dm7zJEPmVvOI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}